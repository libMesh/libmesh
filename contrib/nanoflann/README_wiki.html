<html>
<head>
<title>nanoflann - Web content</title>
</head>
<body>
<p><small>The most up-to-date version of this page will be always available at: 
<a href="http://code.google.com/p/nanoflann/">http://code.google.com/p/nanoflann/</a></small></p><hr>

<h1><a name="1._About"></a>1. About<a href="#1._About" class="section_anchor"></a></h1><hr/><p><tt>nanoflann</tt> is a <strong>C++ <a href="http://en.wikipedia.org/wiki/Header-only" rel="nofollow">header-only</a> library</strong> for building KD-Trees, mostly optimized for 2D or 3D point clouds. Queries for neighbors around any arbitrary location in space can then be solved quickly and efficiently using <strong>Approximate Nearest Neighbor</strong> (<a href="http://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximate_nearest_neighbor" rel="nofollow">ANN</a>) algorithms. </p><p><tt>nanoflann</tt> does not require compiling or installing, just an <tt>#include &lt;nanoflann.hpp&gt;</tt> in your code. </p><p>This library is a <strong>fork (and a subset) of the <a href="http://people.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN" rel="nofollow">`flann` library</a></strong>, by Marius Muja and David G. Lowe, born as a child project of <a href="http://www.mrpt.org/" rel="nofollow">MRPT</a>. Following the original license terms, <tt>nanoflann</tt> is distributed under the BSD license. If you want to contact <a href="https://sites.google.com/site/jlblancosite/" rel="nofollow">me</a> for reporting any issue or patch, write to joseluisblancoc@gmail.com </p><h2><a name="1.1._Obtaining_the_code"></a>1.1. Obtaining the code<a href="#1.1._Obtaining_the_code" class="section_anchor"></a></h2><ul><li><strong>Latest stable release:</strong> (Feb 1st, 2012) </li><ul><li><a href="http://nanoflann.googlecode.com/files/nanoflann-1.1.1.tar.gz" rel="nofollow">nanoflann-1.1.1.tar.gz</a> </li><li><a href="http://nanoflann.googlecode.com/files/nanoflann-1.1.1.zip" rel="nofollow">nanoflann-1.1.1.zip</a> </li></ul></ul><ul><li><strong>PPA Ubuntu repositories</strong> (<a href="https://launchpad.net/~joseluisblancoc/+archive/nanoflann" rel="nofollow">web</a>): </li><pre class="prettyprint">sudo add-apt-repository ppa:joseluisblancoc/nanoflann
sudo apt-get update
sudo apt-get install libnanoflann-dev</pre></ul><ul><li>Unstable SVN version (<a href="http://nanoflann.googlecode.com/svn/trunk/" rel="nofollow">browse online</a>): </li><pre class="prettyprint">   # Check out a read-only working copy anonymously over HTTP:
   svn checkout http://nanoflann.googlecode.com/svn/trunk/ nanoflann-svn</pre></ul><h2><a name="1.2._C++_API_reference"></a>1.2. C++ API reference<a href="#1.2._C++_API_reference" class="section_anchor"></a></h2><ul><li><a href="http://nanoflann-reference.mrpt.org/svn/" rel="nofollow">http://nanoflann-reference.mrpt.org/svn/</a> </li></ul><h2><a name="1.3._Why_a_fork?"></a>1.3. Why a fork?<a href="#1.3._Why_a_fork?" class="section_anchor"></a></h2><ul><li><strong>Execution time efficiency</strong>:  </li><ul><li>The power of the original <tt>flann</tt> library comes from the possibility of choosing between different ANN algorithms. The cost to pay is the declaration of pure virtual methods, which (in some circumstances) impose <a href="http://www.cs.cmu.edu/~gilpin/c%2B%2B/performance.html#virtualfunctions" rel="nofollow">run-time penalties</a>. In <tt>nanoflann</tt> all those virtual methods have been replaced by a combination of the <a href="http://en.wikipedia.org/wiki/Curiously_recurring_template_pattern" rel="nofollow">Curiously Recurring Template Pattern</a> (CRTP) and inlined methods, which are much faster.  </li><li>For <tt>radiusSearch()</tt>, there is no need anymore to make a first call to determine the number of points within the radius, then call it again to get the data. By using STL containers for the output data, containers are automatically resized. </li><li>Users can (optionally) fix the problem dimensionality at compile-time via a template argument, thus allowing the compiler to fully unroll loops. </li><li>Also, <tt>nanoflann</tt> allows users to provide a precomputed bounding box of the data, if available, to avoid recomputing it again. </li><li>Indices of data points have been converted from <tt>int</tt> to <tt>size_t</tt>, which removes a limit when handling very large data sets. </li></ul></ul><ul><li><strong>Memory efficiency</strong>: Instead of making a copy of the entire dataset into a custom <tt>flann</tt>-like matrix before building a KD-tree index, <tt>nanoflann</tt> allows you to directly working on your class data via an <strong>adaptor interface</strong> which must be implemented in your class.  </li></ul><p>Refer to the examples below or to the C++ API of <a href="http://nanoflann-reference.mrpt.org/svn/classnanoflann_1_1KDTreeSingleIndexAdaptor.html" rel="nofollow">nanoflann::KDTreeSingleIndexAdaptor&lt;&gt;</a> for more info. </p><h2><a name="1.4._What_can_nanoflann_do?"></a>1.4. What can <tt>nanoflann</tt> do?<a href="#1.4._What_can_nanoflann_do?" class="section_anchor"></a></h2><ul><li>Building KD-trees with a single index (no randomized KD-trees). </li><li>Fast querying for neighbors on KD-trees. The two main entry points are: </li><ul><li><a href="http://nanoflann-reference.mrpt.org/svn/classnanoflann_1_1KDTreeSingleIndexAdaptor.html" rel="nofollow">nanoflann::KDTreeSingleIndexAdaptor&lt;&gt;</a><tt>::knnSearch()</tt> </li><li><a href="http://nanoflann-reference.mrpt.org/svn/classnanoflann_1_1KDTreeSingleIndexAdaptor.html" rel="nofollow">nanoflann::KDTreeSingleIndexAdaptor&lt;&gt;</a><tt>::radiusSearch()</tt> </li></ul><li>Define the dimensionality of the data at compile time, easing the generation of optimized code by the compiler. </li><li>Work with 2D and 3D point clouds or N-dimensional data sets. </li><li>Directly work with <tt>Eigen::Matrix&lt;&gt;</tt> classes. </li><li>Work with the distance metrics: <tt>L1</tt> (Manhattan), <tt>L2</tt> (Euclidean, favoring SSE2 optimization) and <tt>L2_Simple</tt> (Euclidean, for low-dimensionality data sets like point clouds). </li></ul><h2><a name="1.5._What_can&#x27;t_nanoflann_do?"></a>1.5. What can&#x27;t <tt>nanoflann</tt> do?<a href="#1.5._What_can&#x27;t_nanoflann_do?" class="section_anchor"></a></h2><ul><li>Using other distance metrics apart from L1 and L2. </li><li>Only the C++ interface exists: there is no support for C, MATLAB or Python. </li><li>There is no automatic algorithm configuration (as described in the original Muja &amp; Lowe&#x27;s paper). </li><li>The data in the source (data set) object is assumed <strong>not to vary</strong> during the execution of kd-tree queries. If this cannot be assured, the data set should be duplicated by the user and <tt>nanoflann</tt> applied to the copy. However, this is not the case in many practical applications. </li></ul><h2><a name="1.6._Code_examples"></a>1.6. Code examples<a href="#1.6._Code_examples" class="section_anchor"></a></h2><ul><li>KD-tree look-up with kdd_search() and radius_search(): <a href="http://nanoflann.googlecode.com/svn/trunk/examples/pointcloud_kdd_radius.cpp" rel="nofollow">pointcloud_kdd_radius.cpp</a> </li><li>KD-tree look-up on a point cloud dataset: <a href="http://nanoflann.googlecode.com/svn/trunk/examples/pointcloud_example.cpp" rel="nofollow">pointcloud_example.cpp</a> </li><li>KD-tree look-up on a point cloud dataset with an external adaptor class: <a href="http://nanoflann.googlecode.com/svn/trunk/examples/pointcloud_adaptor_example.cpp" rel="nofollow">pointcloud_adaptor_example.cpp</a> </li><li>KD-tree look-up directly on an Eigen::Matrix&lt;&gt;: <a href="http://nanoflann.googlecode.com/svn/trunk/examples/matrix_example.cpp" rel="nofollow">matrix_example.cpp</a> </li></ul><ul><li>Example with a <tt>Makefile</tt> for usage through <tt>pkg-config</tt> (for example, after doing a &quot;make install&quot; or after installing from Ubuntu repositories): <a href="http://nanoflann.googlecode.com/svn/trunk/examples/example_with_pkgconfig/" rel="nofollow">example_with_pkgconfig/</a> </li></ul><p><br><br> </p><h1><a name="2._Any_help_choosing_the_KD-tree_parameters?"></a>2. Any help choosing the KD-tree parameters?<a href="#2._Any_help_choosing_the_KD-tree_parameters?" class="section_anchor"></a></h1><hr/><h2><a name="2.1._KDTreeSingleIndexAdaptorParams::leaf_max_size"></a>2.1. <tt>KDTreeSingleIndexAdaptorParams::leaf_max_size</tt><a href="#2.1._KDTreeSingleIndexAdaptorParams::leaf_max_size" class="section_anchor"></a></h2><p>A KD-tree is... well, a tree :-). And as such it has a root node, a set of intermediary nodes and finally, &quot;leaf&quot; nodes which are those without children.  </p><p>Points (or, properly, point indices) are only stored in leaf nodes. Each leaf contains a list of which points fall within its range. </p><p>While building the tree, nodes are recursively divided until the number of points inside is equal or below some threshold. <strong>That is <tt>leaf_max_size</tt></strong>. While doing queries, the  &quot;tree algorithm&quot; ends by selecting leaf nodes, then performing linear search (one-by-one) for the closest point to the query within all those in the leaf. </p><p>So, <tt>leaf_max_size</tt> must be set as a <strong>tradeoff</strong>:  <ul><li>Large values mean that the tree will be built faster (since the tree will be smaller), but each query will be slower (since the linear search in the leaf is to be done over more points). </li><li>Small values will build the tree much slower (there will be many tree nodes), but queries will be faster... up to some point, since the &quot;tree-part&quot; of the search (logarithmic complexity) still has a significant cost. </li></ul></p><p>What number to select really depends on the application and even on the size of the processor cache memory, so ideally you should do some benchmarking for maximizing efficiency.  </p><p>But to help choosing a good value as a rule of thumb, I provide the following two benchmarks. Each graph represents the tree build (horizontal) and query (vertical) times for different <tt>leaf_max_size</tt> values between 1 and 10K (as 95% uncertainty ellipses, deformed due to the logarithmic scale). </p><ul><li>A 100K point cloud, uniformly distributed (each point has (x,y,z) <tt>float</tt> coordinates): </li></ul><p><img src="http://nanoflann.googlecode.com/svn/trunk/doc/perf5_1e5pts_time_vs_maxleaf.png" /> </p><ul><li>A ~150K point cloud from a real dataset (<tt>scan_071_points.dat</tt> from the <a href="http://ais.informatik.uni-freiburg.de/projects/datasets/fr360/" rel="nofollow">Freiburg Campus 360 dataset</a>, each point has (x,y,z) <tt>float</tt> coordinates): </li></ul><p><img src="http://nanoflann.googlecode.com/svn/trunk/doc/perf5_1e5pts_time_vs_maxleaf_real_dataset.png" /> </p><p>So, it seems that a <tt>leaf_max_size</tt> <strong>between 10 and 50</strong> would be optimum in applications where the cost of queries dominates (e.g. <a href="http://en.wikipedia.org/wiki/Iterative_closest_point" rel="nofollow">ICP</a>). At present, its default value is 10. </p><p><br> </p><h2><a name="2.2._KDTreeSingleIndexAdaptorParams::checks"></a>2.2. <tt>KDTreeSingleIndexAdaptorParams::checks</tt><a href="#2.2._KDTreeSingleIndexAdaptorParams::checks" class="section_anchor"></a></h2><p>This parameter is really ignored in <tt>nanoflann</tt>, but was kept for backward compatibility with the original FLANN interface. Just ignore it. </p><p><br><br> </p><h1><a name="3._Performance"></a>3. Performance<a href="#3._Performance" class="section_anchor"></a></h1><hr/><h2><a name="3.1._nanoflann_:_faster_and_less_memory_usage"></a>3.1. <tt>nanoflann</tt>: faster and less memory usage<a href="#3.1._nanoflann_:_faster_and_less_memory_usage" class="section_anchor"></a></h2><p>Refer to the &quot;Why a fork?&quot; section above for the main optimization ideas behind <tt>nanoflann</tt>. </p><p>Notice that there are no explicit SSE2/SSE3 optimizations in <tt>nanoflann</tt>, but the intensive usage of <tt>inline</tt> and templates in practice turns into automatically SSE-optimized code generated by the compiler. </p><h2><a name="3.2._Benchmark:_original_flann_vs_nanoflann"></a>3.2. Benchmark: original <tt>flann</tt> vs <tt>nanoflann</tt><a href="#3.2._Benchmark:_original_flann_vs_nanoflann" class="section_anchor"></a></h2><p>The most time-consuming part of many point cloud algorithms (like ICP) is querying a KD-Tree for nearest neighbors. This operation is therefore the most time critical.  </p><p><tt>nanoflann</tt> provides a ~50% time saving with respect to the original <tt>flann</tt> implementation (times in this chart are in microseconds for each query): </p><p><img src="http://nanoflann.googlecode.com/svn/trunk/doc/perf3_query.small.png" /> </p><p>Although most of the gain comes from the queries (due to the large number of them in any typical operation with point clouds), there is also some time saved while building the KD-tree index, due to the templatized-code but also for the avoidance of duplicating the data in an auxiliary matrix (times in the next chart are in milliseconds): </p><p><img src="http://nanoflann.googlecode.com/svn/trunk/doc/perf4_time_saved.small.png" /> </p><p>These performance tests are only orientative. If you want to repeat them, read the instructions in <a href="http://nanoflann.googlecode.com/svn/trunk/perf-tests/" rel="nofollow">http://nanoflann.googlecode.com/svn/trunk/perf-tests/</a> </p><p><br> </p><h1><a name="4._Other_KD-tree_projects"></a>4. Other KD-tree projects<a href="#4._Other_KD-tree_projects" class="section_anchor"></a></h1><hr/><ul><li><a href="http://people.cs.ubc.ca/~mariusm/index.php/FLANN/FLANN" rel="nofollow">FLANN</a> - Marius Muja and David G. Lowe (University of British Columbia). </li><li><a href="http://www.robots.ox.ac.uk/~vgg/software/fastann/" rel="nofollow">FASTANN</a> - James Philbin (VGG, University of Oxford). </li><li><a href="http://www.cs.umd.edu/~mount/ANN/" rel="nofollow">ANN</a> - David M. Mount and Sunil Arya (University of Maryland). </li><li><a href="http://libkdtree.alioth.debian.org/" rel="nofollow">libkdtree++</a> - Martin F. Krafft &amp; others. </li></ul><p><br><br> <i>Note: The project logo is due to <a href="http://www.iconarchive.com/show/patisserie-icons-by-cedarseed/Flan-icon.html" rel="nofollow">CedarSeed</a></i> </p>

</body>
</html>